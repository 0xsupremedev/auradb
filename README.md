# AuraDB ğŸš€

A high-performance Rust storage engine that combines **WAL-time Key-Value separation**, **RL-driven adaptive compaction**, and **learned indexes** to rival and surpass RocksDB performance.

## ğŸ¯ Key Innovations

### 1. WAL-time Key-Value Separation (BVLSM-inspired)
- **Why**: Classic LSM engines copy large values repeatedly during flush/compaction, causing high write amplification
- **How**: Large values are immediately written to a separate value log at WAL time, while only keys and pointers go to the LSM tree
- **Benefits**: 7.6Ã— higher throughput on 64KB random writes vs RocksDB, reduced memory pressure, stable I/O patterns

### 2. RL-driven Adaptive Compaction (RusKey-inspired)
- **Why**: Static compaction policies struggle with dynamic workloads
- **How**: Reinforcement learning agent continuously tunes LSM structure between tiered/leveled modes
- **Benefits**: Up to 4Ã— better end-to-end performance under changing workloads, reduced tail latency

### 3. Learned Indexes (DobLIX-inspired)
- **Why**: Traditional indexes can be slow and memory-intensive
- **How**: Machine learning models predict data location with fallback to binary search
- **Benefits**: 1.19Ã—â€“2.21Ã— throughput improvement, 70% faster than cache-optimized B-trees

## ğŸ—ï¸ Architecture

```
Client API (KV + optional SQL-ish ops)
  â””â”€â”€ Router (point/scan/batch/txn)
      â”œâ”€â”€ Txn/TSO (optional MVCC)
      â”œâ”€â”€ Read Path
      â”‚    â”œâ”€â”€ Learned Index Tier (+ fallback)
      â”‚    â”œâ”€â”€ Block Cache (+ Bloom/Ribbon filters)
      â”‚    â””â”€â”€ SST Manager (point/range reads)
      â””â”€â”€ Write Path
           â”œâ”€â”€ WAL-time KV Separation (KV router)
           â”‚    â”œâ”€â”€ WAL (keys + meta only)
           â”‚    â””â”€â”€ Value Log (separate big values)
           â”œâ”€â”€ Memtable(s) (skiplist/ART)
           â””â”€â”€ Flush & SST Builder

Background services
  â”œâ”€â”€ RL Compaction Orchestrator (policy + scheduler)
  â”œâ”€â”€ GC for Value Log (live-pointer tracing)
  â”œâ”€â”€ Learned Index Trainer/Tuner (online/offline)
  â”œâ”€â”€ IO Scheduler (rate limit, debt accounting)
  â””â”€â”€ Telemetry + Self-tuning (A/B configs)

Storage
  â”œâ”€â”€ SST files (tiered LSM)
  â”œâ”€â”€ Value log segments
  â””â”€â”€ Manifests + snapshots
```

## ğŸš€ Quick Start

### Prerequisites
- Rust 1.70+ 
- Linux/macOS/Windows

### Installation

```bash
# Clone the repository
git clone https://github.com/auradb/auradb.git
cd auradb

# Build the project
cargo build --release

# Run tests
cargo test

# Run the example
cargo run --example basic_usage
```

### Basic Usage

```rust
use auradb::prelude::*;

#[tokio::main]
async fn main() -> Result<()> {
    // Create engine
    let engine = EngineBuilder::new()
        .with_db_path("/path/to/db".into())
        .build()
        .await?;
    
    // Basic operations
    engine.put_str("key1", "value1").await?;
    let value = engine.get_str("key1").await?;
    println!("Value: {:?}", value);
    
    // Range scan
    let results = engine.scan_str("a", "z", Some(100)).await?;
    
    // Clean up
    engine.close().await?;
    Ok(())
}
```

## ğŸ“Š Performance Targets

| Metric | Target | vs RocksDB |
|--------|--------|-------------|
| Large-value writes | â‰¥2Ã— throughput | BVLSM effect |
| Dynamic workloads | â‰¥1.5â€“3Ã— p99 stability | RL compaction |
| Point reads | ~1.2â€“2Ã— throughput | Learned indexes |
| Memory usage | Equal or lower | Efficient structures |

## ğŸ› ï¸ Configuration

### Basic Configuration

```rust
use auradb::config::Config;

let config = Config::new()
    .with_db_path("/path/to/db".into())
    .with_wal(WalConfig {
        max_file_size: 64 * 1024 * 1024, // 64MB
        async_writes: true,
        ..Default::default()
    })
    .with_value_log(ValueLogConfig {
        separation_threshold: 1024, // 1KB
        max_segment_size: 256 * 1024 * 1024, // 256MB
        ..Default::default()
    });

let engine = create_engine_with_config(config).await?;
```

### Advanced Configuration

```rust
let engine = AdvancedEngineBuilder::new()
    .with_db_path("/path/to/db".into())
    .with_memtable_config(MemtableConfig {
        implementation: MemtableImpl::SkipList,
        max_size: 128 * 1024 * 1024, // 128MB
        ..Default::default()
    })
    .with_learned_index_config(LearnedIndexConfig {
        model_type: ModelType::PiecewiseLinear,
        online_tuning: true,
        ..Default::default()
    })
    .with_rl_agent_config(RlAgentConfig {
        learning_rate: 0.01,
        exploration_rate: 0.1,
        ..Default::default()
    })
    .build()
    .await?;
```

## ğŸ”§ Core Components

### 1. WAL (Write-Ahead Log)
- Append-only log with configurable sync policies
- Async writes for high throughput
- Automatic file rotation

### 2. Value Log
- Parallel write queues for high throughput
- Compression support (LZ4, Zstd, Snappy)
- Automatic segment rotation

### 3. Memtable
- Multiple implementations: SkipList, ART, B-tree
- Lock-free operations where possible
- Automatic flushing based on size thresholds

### 4. SST Manager
- Multi-level LSM structure
- Configurable block sizes and compression
- Bloom/Ribbon filters for fast lookups

### 5. Compaction
- Flexible LSM (FLSM) supporting tiered/leveled modes
- RL-driven policy selection
- I/O rate limiting and debt accounting

### 6. Learned Indexes
- Piecewise linear regression models
- Online tuning and validation
- Fallback to traditional search methods

## ğŸ“ˆ Roadmap

### M0 â€“ Core Skeleton (2â€“3 weeks) âœ…
- [x] Basic WAL and memtable
- [x] Simple flush to SST (no compaction)
- [x] Basic block cache and Bloom filters

### M1 â€“ WAL-time KV Separation (BVLSM-lite) âœ…
- [x] Value log implementation
- [x] WAL-time separation logic
- [x] Async value log writes

### M2 â€“ Basic Compaction (Tiered+Leveled) ğŸš§
- [ ] Tiered and leveled compaction
- [ ] I/O budgeting and admission control
- [ ] Manual policy switching

### M3 â€“ RL Agent (RusKey-style) ğŸ“‹
- [ ] RL agent implementation
- [ ] State observation and action selection
- [ ] Safety fallbacks and rollbacks

### M4 â€“ Learned Indexes (DobLIX-style) ğŸ“‹
- [ ] Piecewise linear models
- [ ] Online tuner and validation
- [ ] Fallback search methods

### M5 â€“ Production Features ğŸ“‹
- [ ] Value log GC
- [ ] Crash recovery and snapshots
- [ ] Backup and restore

### M6 â€“ Optimization ğŸ“‹
- [ ] NUMA-aware threading
- [ ] Advanced QoS and admission control
- [ ] Encryption and advanced compression

## ğŸ§ª Testing & Benchmarks

### Running Tests
```bash
# Unit tests
cargo test

# Integration tests
cargo test --test integration

# Benchmarks
cargo bench
```

### Benchmarking
```bash
# YCSB-style workloads
cargo run --bin benchmark -- --workload ycsb

# Custom traces
cargo run --bin benchmark -- --trace-file workload.trace

# Comparison with RocksDB
cargo run --bin benchmark -- --compare-rocksdb
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup
```bash
# Clone and setup
git clone https://github.com/auradb/auradb.git
cd auradb

# Install development dependencies
cargo install cargo-watch
cargo install cargo-audit

# Run development server
cargo watch -x check -x test -x run
```

### Code Style
- Follow Rust formatting guidelines (`cargo fmt`)
- Run clippy (`cargo clippy`)
- Ensure all tests pass
- Add tests for new functionality

## ğŸ“š Documentation

- [API Reference](https://docs.rs/auradb)
- [Architecture Guide](docs/architecture.md)
- [Performance Tuning](docs/performance.md)
- [Troubleshooting](docs/troubleshooting.md)

## ğŸ”¬ Research & References

This project builds on several key research papers:

- **BVLSM**: WAL-time Key-Value separation for LSM engines
- **RusKey**: RL-driven compaction for dynamic workloads  
- **DobLIX**: Dual-objective learned indexes for LSM engines
- **Learned Indexes**: Machine learning for data structures

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
