searchState.loadedDescShard("criterion", 0, "A statistics-driven micro-benchmarking library written in …\nRun all benchmarks.\nCriterion.rs should choose a sampling method …\nAxis scaling type\nBaseline describes how the baseline_directory is handled.\nArgument to <code>Bencher::iter_batched</code> and …\nTimer struct used to iterate a benchmarked function and …\nBenchmark filtering support.\nStructure used to group together a set of related …\nSimple structure representing an ID for a benchmark. The …\nMeasure throughput in terms of bytes/second. The value …\nEquivalent to Bytes, but the value will be reported in …\nCompareLenient compares against a previous saved version …\nCompareStrict compares against a previous saved version of …\nThe benchmark manager\nDiscard benchmark results.\nMeasure throughput in terms of elements/second. The value …\nRun the benchmark matching this string exactly.\nKeep the iteration count the same for all samples. This is …\nPlotting backend which uses the external <code>gnuplot</code> command …\n<code>LargeInput</code> indicates that the input to the benchmark …\nAxes scale linearly\nScale the iteration count in each sample linearly. This is …\nAxes scale logarithmically\nNull plotting backend which outputs nothing,\n<code>NumBatches</code> will attempt to divide the iterations up into a …\n<code>NumIterations</code> fixes the batch size to a constant number, …\n<code>PerIteration</code> indicates that the input to the benchmark …\nContains the configuration options for the plots generated …\nPlotting backend which uses the rust ‘Plotters’ …\nEnum used to select the plotting backend.\nRun benchmarks matching this regex.\nDo not run any benchmarks.\nThis enum allows the user to control how Criterion.rs …\nSave writes the benchmark results to the baseline …\n<code>SmallInput</code> indicates that the input to the benchmark …\nEnum representing different ways of measuring the …\nThis module defines a trait that can be used to plug in …\nBenchmark the given parameterless function inside this …\nBenchmarks a function. For comparing multiple functions, …\nBenchmark the given parameterized function inside this …\nBenchmarks a function with an input. For comparing …\nReturn a benchmark group. All benchmarks performed using a …\nA function that is opaque to the optimizer, used to …\nChanges the confidence level for benchmarks in this group. …\nChanges the default confidence level for benchmarks run …\nConfigure this criterion struct based on the command-line …\nMacro used to define a function group for the benchmark …\nMacro which expands to a benchmark harness.\nCreates a benchmark manager with the following default …\nConsume the benchmark group and generate the summary …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nConstruct a new benchmark ID from just a parameter value. …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nTimes a <code>routine</code> by executing it many times and timing the …\nTimes a <code>routine</code> that requires some input by generating a …\nTimes a <code>routine</code> that requires some input by generating a …\nTimes a <code>routine</code> by executing it many times and relying on …\nTimes a <code>routine</code> by collecting its output on each …\nThis module defines a set of traits that can be used to …\nChanges the target measurement time for this benchmark …\nChanges the default measurement time for benchmarks run …\nConstruct a new benchmark ID from a string function name …\nChanges the noise threshold for benchmarks in this group. …\nChanges the default noise threshold for benchmarks run …\nChanges the number of resamples for this benchmark group\nChanges the default number of resamples for benchmarks run …\nChanges the plot configuration for this benchmark group.\nSet the plotting backend. By default, Criterion will use …\nThis module provides an extension trait which allows …\nNames an explicit baseline and disables overwriting the …\nChanges the size of the sample for this benchmark\nChanges the default size of the sample for benchmarks run …\nSet the sampling mode for this benchmark group.\nNames an explicit baseline and enables overwriting the …\nChanges the significance level for benchmarks in this …\nChanges the default significance level for benchmarks run …\nSet the axis scale (linear or logarithmic) for the summary …\nSet the input size for this benchmark group. Used for …\nChanges the warm up time for this benchmark\nChanges the default warm up time for benchmarks run with …\nOnly run benchmarks specified by the given filter.\nFilters the benchmarks. Only benchmarks with names that …\nChanges the measurement for the benchmarks run with this …\nOverride whether the CLI output will be colored or not. …\nEnables plotting\nChanges the internal profiler for benchmarks run with this …\nDisables plotting\nPlugin trait used to allow benchmarking on multiple …\nSpawn the given future onto this runtime and block until it…\nThis type represents an intermediate value for the …\nTrait for all types which define something Criterion.rs …\nThis type is the measured value. An example might be the …\nTrait providing functions to format measured values to …\n<code>WallTime</code> is the default measurement in Criterion.rs. It …\nCombine two values. Criterion.rs sometimes needs to …\nCriterion.rs will call this after iterating the benchmark …\nFormat the value as a throughput measurement. The value …\nFormat the value (with appropriate unit) and return it as …\nReturn a trait-object reference to the value formatter for …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nScale the values and return a unit string designed for …\nConvert the given measured values into throughput numbers …\nScale the given values to some appropriate unit and return …\nCriterion.rs will call this before iterating the benchmark.\nConverts the measured value to f64 so that it can be used …\nReturn a “zero” value for the Value type which can be …\nDummy profiler implementation, representing cases where …\nExtension trait for external crates to implement which …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThis function is called when Criterion.rs starts profiling …\nThis function is called after Criterion.rs stops profiling …")